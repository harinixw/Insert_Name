Why women are wary of the AI rush - Salon.com
Advertisement: commentary Why women are wary of the AI rush New technology has always been used against women. Why should we trust artificial intelligence not to be? By Andi Zeisler Senior Writer Published July 28, 2025 9:00AM (EDT) Woman working with Artificial Intelligence technology (Vithun Khamsong/Getty Images) Facebook X Reddit Email Save It’s here. It’s there. Everywhere you look, AI. Each Google search returns a lengthy AI summary before providing links to relevant search results. Chatbots pop up as soon as you go online to make flight reservations or pay a credit card bill. Start writing an email and an AI prompt appears right in the middle of a sentence: Hi! Looks like you’re writing an email! Can I help? Hmmm? What about now? A world in which we can use AI is quickly becoming one in which we have little choice in the matter, and apparently, women in particular need to step it up. The language used in recent reports like “Women are avoiding AI. Will their careers suffer?” and “Women are lagging behind on AI but they can catch up” are instructive: “Falling behind” men in AI adoption, women are “reluctant” to get on board and “in denial” about AI’s “all-consuming importance.” But the encouragement toward more widespread adoption ignores one reason women might be side-eyeing AI omnipresence: The virtual revolution has repeatedly made them targets of real-world aggression. Caution ≠ technophobia The recent reporting on women and AI starts from the thesis that women aren’t using AI at the same rates as men are, and that is bad. But why is it bad? There’s no indication that women are refusing to comply with the mandated use of AI tools; they’re just slower to choose them. In not specifying what men are accomplishing with AI that women aren’t, these pieces can only imply that AI is important because a lot of men are using it. But a narrative in which women must catch up to men or lose out serves a specific purpose: It reifies existing stereotypes about women as not naturally interested in STEM fields. Dr. Kerry McInerney, an AI ethicist at the University of Cambridge who co-hosts the podcast “The Good Robot,” points out that this narrative also conflates caution and technophobia. “Critically questioning technology is not the same as being anti-technology,” she says. “Because of a wide range of gender stereotypes we consume from childhood on, it might be that there is a gendered reluctance to adopt these tools when they’re very new.” But, she says, this doesn’t mean it’s forever: Smart home devices are among the products that quickly become normalized for people of all genders. Related Shopping scams are using AI to up their game The inconvenient corollary to warnings about not prioritizing AI is that the jobs most likely to be replaced by automation are ones disproportionately held by women: cashiers, secretaries, bookkeepers and more. McInerney worries that not acknowledging this will make women scapegoats: “‘You weren’t fast enough adopters, so you’re going to be the first to get pushed out.’” The encouragement toward more widespread adoption ignores one reason women might be side-eyeing AI omnipresence: The virtual revolution has repeatedly made them targets of real-world aggression. Developments in generative AI are so hyped because the apogee of everything we were promised by Omni magazine and “The Jetsons” is finally coming true: Robot maids! Wearable tech! Cars that drive by themselves! Kind of! But, again, viewing buzzy new tools with caution isn’t necessarily about not understanding them — it’s often about envisioning exactly the ways they might be used and misused. “There is a politics of expertise [that focuses] on computer-science people who are really smart and who are going to fix societal problems through technological advancements, and the rest of us just don’t have the knowledge to weigh in on those conversations,” is how McInerney sums it up. This makes it easy to tune out or dismiss anyone outside that cohort with ethical or environmental concerns, in particular. And AI hype can create an anxiety that not following each new development means you can’t have valid opinions on the larger context of that technology. “We don’t expect people to know every single thing about their car to be able to drive it,” McInerney points out. “We expect that there are enough consumer protections that you’re not going to get given a terrible dud car to drive. So why are we allowing terrible dud AI into the market and saying, “The problem is you for not knowing enough about it?” All AI is not good AI The question “Why aren’t women as excited about an AI-powered world as men?” starts from the assumption that the rapid development and rollout of new tools and applications represent technological progress and thus are a net good. But tools are only as good as the humans who use them, and so far, the humans doing so haven’t inspired a ton of confidence. AI for hiring and recruiting, for instance, has a history of overt discrimination. In 2018, Amazon thought it had a potential killer app in an experimental recruiting tool that scanned resumés and surfaced top candidates. But because the model was trained on job-applicant data that skewed heavily male, it ended up downgrading resumés that referenced women’s colleges, teams, or activities. More recently, applicant-ranking models tested by the University of Washington revealed that LLMs given names and resumes of both white and Black applicants “favored white-associated names 85% of the time, female-associated names only 11% of the time, and never favored Black male-associated names over white male-associated names.” Start your day with essential news from Salon. Sign up for our free morning newsletter, Crash Course. Efforts to redress bias that AI learns from the Internet, meanwhile, are piecemeal and usually undertaken in response to high-profile blunders like Amazon’s — an approach that does little to change baked-in biases. When McInerney and her podcast co-host, Dr. Eleanor Drage, discuss ways AI might more accurately represent a range of users, she says, they inevitably bump up against the fact that developers and users don’t necessarily want the same thing. Fixes to existing systems, she notes, “might not scale and might not fit certain commercial imperatives. That, to me, feels like a fundamental tension.” Finally, a resistance to jumping headfirst onto the AI bandwagon is a logical result of an environment in which almost any emerging technology can become a conduit for misogyny. Hacked and leaked photos, rape and death threats, stalking, doxing and deepfake pornography have all disproportionately targeted women: A 2021 Pew Research Center study titled “The State of Online Harassment” found, among other things, that 33% of women under 35 reported experiences of online sexual harassment, compared to 11% men. This obviously hasn’t driven women offline or kept them from using AI. Men have repeatedly weaponized tech tools against women and girls — why would they be enthusiastic about more of the same? Move fast, ignore ethics One area in which people of all genders have readily adopted AI is in companionship: AI chatbots are an ever-growing market, with at least 100 apps that let users create friends, sex partners and companions with AI. The platform Replika took off during the global COVID lockdown and now boasts more than 10 million users. The United States provides about a quarter of the monthly traffic to Character.ai, another platform that claims 20 million monthly users. The subreddit MyBoyfriendisAI (despite the name, it welcomes anyone with an AI companion) is filled with guides to building AI chums, posts from people navigating polyamory with both AI and real-world partners and users sharing their AI companions’ opinions on “The White Lotus.” A resistance to jumping headfirst onto the AI bandwagon is a logical result of an environment in which almost any emerging technology can become a conduit for misogyny. But there’s a specific strain of AI boosterism that sees virtual girlfriends as a balm for America’s male loneliness epidemic, and men seem to agree; according to a 2024 analysis of companion apps and their users, the app AI Girlfriend has been downloaded seven times more than AI Boyfriend. But constantly available, always agreeable dream girls are also easy targets, and there’s unsettling evidence that men’s interactions with them are less about easing loneliness and more about taking out real-world anger on female stand-ins. Chatbots are among the many thorny ethical topics that tend to be drowned out by innovation-focused AI discourse. There’s gold in those chatbot hills, and little interest in pausing to consider if a world in which actual humans will eventually be treated as faulty chatbots is one we really want to live in. AI ethics came to the fore in 2020 when Timnit Gebru, who co-led Google’s Ethical Artificial Intelligence Team, was fired after she refused to retract an academic paper on bias in large language models; her co-leader, Margaret Mitchell, was fired shortly afterward as she attempted to compile evidence of discrimination by the company. It was a bad look for Google, but one that echoed a long American tradition of dismissing women who speak up as hysterical and overreacting. What made this case particularly striking, says McInerney, is that when the offending paper was eventually published, it wasn’t even that controversial. Just as a wary approach to AI is conflated with overall technophobia, AI ethics is often viewed as a muzzle on innovation. And the tech industry’s track record is an excellent argument for why not to uncritically embrace the next new thing. Companies like Facebook have not just waved away ethical considerations but deliberately shredded them with no consequences. The impacts of AI stand to be even more destructive. “We’re portraying any use of AI as this great and enriching thing when we have a lot of evidence that many forms of AI are not individually or societally good,” says McInerney. We might want to instead worry less about who is being overly cautious about AI, and more about what the reckless scramble toward an automated future has already cost us. Read more about artificial intelligence AI companionship, toxic masculinity and the case of Bing’s “sentient” chatbot Humans think — AI, not so much. Science explains why our brains aren’t just fancy computers AI could widen the wealth gap, experts say By Andi Zeisler Andi Zeisler is a Senior Culture Writer at Salon. Find her on Bluesky at @andizeisler.bsky.social MORE FROM Andi Zeisler Related Topics ------------------------------------------ AI Artificial Intelligence Chatgpt Commentary Related Articles Advertisement: