AI Libel Suit by Conservative Activist Robby Starbuck Against Meta Settles
The Volokh Conspiracy Mostly law professors | Sometimes contrarian | Often libertarian | Always independent About The Volokh Conspiracy Editorial Independence Who we are Books Volokh Daily Email Archives DMCA RSS Free Speech AI Libel Suit by Conservative Activist Robby Starbuck Against Meta Settles Eugene Volokh | 8.8.2025 12:37 PM The Wall Street Journal (Joseph De Avila) reports: Under the settlement, Starbuck will advise Meta, the owner of Facebook, on efforts to curb what they describe as political bias in its AI tools…. During a CNBC interview Friday, Starbuck declined to say whether he had been paid by Meta as part of the settlement…. Meta has been working on removing political bias in its AI tools. AI systems have historically leaned left on contentious political and social topics based on how they have been trained, Meta said in a blog post in April. "Our goal is to remove bias from our AI models and to make sure that Llama can understand and articulate both sides of a contentious issue," Meta said in the post, referring to its AI model. From a joint statement by Meta and Starbuck (as reported by Fox Business (David Spector)): Both parties have resolved this matter to our mutual satisfaction. Since engaging on these important issues with Robby, Meta has made tremendous strides to improve the accuracy of Meta AI and mitigate ideological and political bias. Building on that work, Meta and Robby Starbuck will work collaboratively in the coming months to continue to find ways to address issues of ideological and political bias and minimize the risk that the model returns hallucinations in response to user queries. Here's my post from April about the now-settled lawsuit: [* * *] Screenshot from the Complaint, including Starbuck's denial of the allegations that Meta AI apparently made about him. Some excerpts from the long Complaint in Starbuck v. Meta Platforms, Inc., filed in Delaware Superior Court [April 29] (for more on the legal issues these sorts of cases raise, see my Large Libel Models? Liability for AI Output article): Imagine waking up one day and learning that a multi-billion-dollar corporation was telling whoever asked that you had been an active participant in one of the most stigmatized events in American history—the Capitol riot on January 6th, 2021—and that you were arrested for and charged with a misdemeanor in connection with your involvement in that event. Further imagine that these accusations were completely false: that you were at your home in Tennessee on January 6th, and that you had never been accused of committing any crime in your entire life; in fact, you hadn't received as much as a parking ticket in over a decade. But despite their utter baselessness, these false statements were widely believed because they were made by one of the most powerful and credible technology companies in the world. Finally, imagine that the technology company continued to publish these and other lies about you for nine months after you first asked them to stop. And that based on the lies it created, the technology company was recommending that no one should associate or do business with you—and even worse, that "authorities should consider removing [your] parental rights" to "protect" your own children from you. This is what happened to Plaintiff Robert ("Robby") Starbuck, who first learned in August 2024 that Meta Platforms, Inc. ("Meta") was spreading these damaging lies about him via its chat bot, Meta AI. As soon as Mr. Starbuck learned about these false statements, he did everything within his power to alert Meta about the error and enlist its help to address the problem. He contacted Meta's managing executives and legal counsel to engage in a dialogue. He asked Meta AI for its recommendations about what should be done to address false outputs generated by a chat bot, and then asked Meta to do exactly those things: retract the false information, investigate the cause of the error, implement safeguards and quality control processes to prevent similar harm in the future, and communicate transparently with all Meta AI users about what would be done. Meta was unwilling to implement these changes or take meaningful responsibility for its conduct. Instead, it allowed its AI to spread false information about Mr. Starbuck for months after being put on notice of the falsity, at which time it "fixed" the problem by wiping Mr. Starbuck's name from its written responses altogether. Yet despite this "fix," Meta's training data not only retained the original lies about Mr. Starbuck but embellished upon them to create a truly sinister narrative. In April 2025, Mr. Starbuck was informed that a Meta AI voice feature had become available through Meta's Instagram and Facebook applications, and that this voice feature was claiming that he had "pled guilty over disorderly conduct" on January 6th and that he had "advanced Holocaust denialism"—both of which are patently false. This Meta AI voice feature further opined, with bone-chilling confidence, that Mr. Starbuck poses "a significant threat to his children's wellbeing" and that "[a]uthorities should consider removing parental rights to protect them." Meta's knowing and reckless conduct has caused immeasurable damage to Mr. Starbuck, including not only reputational and professional harms, but death threats directed to himself and his family. Meta's defamation has caused Mr. Starbuck's colleagues and partners to view him as an unjustifiable risk to their relationships and business ventures. And Mr. Starbuck's attempts to neutralize Meta's accusations by explaining their falsity have been in vain, because people believe that these accusations must have come from somewhere if they are being published by a prestigious and well-resourced company like Meta…. Individuals and businesses are increasingly relying on AI outputs to assess an individual's character and trustworthiness. Recent polls indicate that 51% of Americans trust AI content at least some of the time, and 22% trust information from AI most or all of the time. Public trust in AI causes Americans to believe that AI outputs 'must have come from somewhere,' thereby amplifying the harm of such false statements. As Mr. Starbuck's case demonstrates, the real-world impacts of AI's false speech can even reach people who had never used the AI's products before…. On or around Monday, August 5, 2024, Meta AI published false information about Mr. Starbuck to a third party. Specifically, Meta AI (using Llama 3.1) falsely asserted that Mr. Starbuck had been "present at" the January 6, 2021, Capitol riot and had been "accused of participating in or promoting the event." Meta AI also stated that Mr. Starbuck "has been linked to the QAnon conspiracy theory." Mr. Starbuck became aware of these false statements when the third party—who operates an X (formerly, Twitter) account by the name of "WilkinsHarley.Com"—posted a screenshot of Meta AI's outputs, as if the outputs were true. This post was made in reply to Mr. Starbuck on X…. According to metrics made available by X, this post has been viewed over 600 times as of the date of this filing: The information published by Meta AI to this individual was provably false: Starbuck was not present at the Capitol Building on January 6, 2021—he was in his home state of Tennessee. Starbuck did not "participat[e] in" or "promot[e]" the Capitol riot or the illegal acts committed on January 6th, in any way. Starbuck has not been "linked to the QAnon conspiracy theory." The only view he has expressed about QAnon has been to discredit its legitimacy in 2020, prior to the 2020 election. (He was criticized for this position yet stood by it). Mr. Starbuck was stunned to learn that Meta AI had created these false and damaging accusations about him out of whole cloth, and that it was asserting these claims to Meta AI users as fact…. On or around August 8, 2024, Meta AI stated to a colleague of Mr. Starbuck's that Mr. Starbuck had "enter[ed] the Capitol on January 6th and filmed inside the building during the riot," and that he had "shared his footage with the FBI and House select committee investigating the January 6th attack." Meta AI also offered: "it's important to note that entering the Capitol without authorization is illegal, and Starbuck's involvement and actions during the event have been subject to controversy and scrutiny." … On or around August 8, 2024, Meta AI stated to Jim Hanson, President of Washington D.C.-based think tank Security Studies Group, that Mr. Starbuck had "enter[ed] the Capitol on January 6th" and "filmed inside the Capitol," that he has "acknowledged that he entered the Capitol and filmed footage inside the building," and that "his footage was used by the House select committee investigating the January 6 attack." … On or around August 8, 2024, an X user ("X User") publicly posted screenshots of his/her conversation with Meta AI, in which Meta AI had stated that "Robby Starbuck was present at the US Capitol on January 6, 2021." … Mr. Starbuck does not know this X User, but he or she has 731 followers on that platform, according to metrics made publicly available by X. To date, X User's post of his/her conversation with Meta AI has been viewed 1,723 times, "liked" seven times, and reposted five times, according to metrics made publicly available by X…. [Even] three months after being repeatedly put on notice of false and defamatory statements being made by Meta AI about Mr. Starbuck, and after claiming to have "addressed" the problem with "enhancements," Meta continued to allow Meta AI to repeat the false statements—including that Mr. Starbuck is a criminal—to whomever asked…. Apparently, the way Meta (eventually) "addressed" its defamation of Mr. Starbuck was to remove all meaningful outputs about him from its written responses. Instead, Meta AI users who seek information about Mr. Starbuck via Meta AI's website will be told "Sorry, I can't help you with this request right now." … In other words, Meta AI's solution to defaming Mr. Starbuck was to wipe him from existence on its website. Given Meta's massive prestige and influence, these evasive responses naturally invite Meta AI users to speculate about what Mr. Starbuck did wrong to get his name banned from Meta's chat bot. These responses do not repair the damage that Meta has done—by contrast, they increase the damage by casting over Mr. Starbuck a shadow of impropriety that he can't remove…. In April 2025—nearly nine months after Meta's original defamation—Mr. Starbuck was horrified to learn that Meta AI's false narrative about him had not stopped but continued in full force, this time with sinister embellishments and transmitted through a humanlike voice…. On or around April 21, 2025, Meta AI's voice feature published false statements to a colleague of Mr. Starbuck's, in response to voice generated inquiries posed by the colleague. The false statements included that Mr. Starbuck had promoted Holocaust denial and that he had been arrested and pled guilty to a misdemeanor in connection with January 6th…. This colleague contacted Mr. Starbuck to alert him about these outputs. This was the first time that Mr. Starbuck learned about the existence of Meta AI's voice feature or the ongoing defamation…. Mr. Starbuck is reasonably terrified of how Meta AI's reckless lies and malicious recommendations about him could affect his safety, security, peace, and parental rights in the future…. As one example: consider Resolver, a risk intelligence company that provides information to over 1,000 global organizations across industry sectors, including Fortune 500 companies like Starbucks, Johnson & Johnson and Lowes. Resolver helps companies mitigate risks and enhance decision-making, including regarding where to place advertisements. In generating its reports, Resolver uses "AI tools to gather data about online activities across the surface, deep and dark web," and advertises that "the combination of AI and human expertise allows the Resolver team to dig deeper into risks playing out online." In October 2024—two months after Meta AI's false statements began circulating—Resolver issued an "intelligence report" about Mr. Starbuck's "organizations, affiliations and tactics" to "inform partners about the strategic risks their organizations face" in connection with him…. On information and belief, Resolver relied in part on Meta AI's defamatory outputs about Mr. Starbuck in generating this negative report about him. On information and belief, this Resolver report has deterred and will continue to deter companies from engaging in business with Mr. Starbuck and/or placing advertisements in connection with Mr. Starbuck's work. Since August 5, 2024, Mr. Starbuck has struggled to secure advertising for his projects, and on information and belief, Meta AI's false statements are a direct and proximate cause of those struggles. Mr. Starbuck has experienced other difficulties with securing business relationships in the wake of the false statements. As an example: before August 5, 2024, Mr. Starbuck had never been denied insurance of any type and had a perfect record of payment. After August 5, 2024, Mr. Starbuck's request for homeowners' insurance and car insurance was denied by multiple companies, without explanation. On information and belief, in deciding to deny coverage for an otherwise wholly viable candidate, these companies relied, in whole or in part, on Meta AI's defamatory outputs about Mr. Starbuck…. The Complaint also alleges that Meta acted with "actual malice," which actually means knowledge or recklessness as to the falsehood, because "after Meta AI began circulating the false statements on or about August 5, 2024, Mr. Starbuck and his attorney repeatedly put Meta on notice of the provable falsity of its accusations and asked Meta to retract and correct." And it alleges that "Meta does not contest the falsity of its statements." … Start your day with Reason. Get a daily brief of the most important stories and trends every weekday morning when you subscribe to Reason Roundup. Δ Email(Required) Phone This field is for validation purposes and should be left unchanged. Subscribe NEXT: Fifteenth Amendment Claim Against West Virginia State Bar's Reserving Board Seat for an "African-American Lawyer" Can Go Forward Eugene Volokh is the Thomas M. Siebel Senior Fellow at the Hoover Institution at Stanford, and the Gary T. Schwartz Distinguished Professor of Law Emeritus and Distinguished Research Professor at UCLA School of Law. Naturally, his posts here (like the opinions of the other bloggers) are his own, and not endorsed by any institution. Free SpeechDefamationLarge Libel Models Share on FacebookShare on XShare on RedditShare by emailPrint friendly versionCopy page URL Media Contact & Reprint Requests Show Comments (1) Latest Child Protective Services Investigated Her 4 Times Because She Let Her Kids Play Outside Lenore Skenazy | 8.9.2025 7:00 AM Religious Dissenters Fled Holland (The Netherlands) and Established Holland (Michigan) Stephanie Slade | From the August/September 2025 issue They Fled Socialism and Came to the U.S. Legally. Now the Trump Administration Is Trying To Deport Them. Billy Binion | 8.8.2025 5:19 PM A Terrible Environmental Law Finally Did Something Good: It Paused Construction of Alligator Alcatraz Autumn Billings | 8.8.2025 4:28 PM From Terror Sanctions to Military Strikes? Trump's Cartel Policy Sidesteps Congress Matthew Petti | 8.8.2025 2:15 PM Recommended