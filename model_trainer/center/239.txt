Your AI Hiring Tool Might Be Racist. Here Are Three Ways To Address AI Bias And Make Hiring More Fair
Leadership Careers Your AI Hiring Tool Might Be Racist. Here Are Three Ways To Address AI Bias And Make Hiring More Fair ByJanice Gassam Asare, Ph.D., Senior Contributor. Forbes contributors publish independent expert analyses and insights. I tell stories about creating environments that empower everyone. Follow Author Aug 08, 2025, 03:07pm EDT Share Save Comment AI hiring tools that end up causing bias can be a costly mistake for employers. getty Many employers use AI tools to help them assess and manage job applicants; one Resume Builder survey indicated that by the end of 2025, 68% of companies will be using AI for hiring. But many of these AI tools are laden with bias, leading to candidates from underrepresented racial groups being filtered out. One 2024 study by Kyra Wilson and Aylin Caliskan revealed that the Massive Text Embedding (MTE) models used by many resume screening tools were biased. The MTE models the researchers analyzed significantly favored white-associated names (in 85.1% of the cases); further analysis also determined that Black males were disadvantaged in 100% of the cases. A 2024 Bloomberg analysis revealed racial bias in OpenAI’s ChatGPT 3.5. According to a Business Insider report, researchers used ChatGPT to screen resumes for jobs, with their analysis indicating that the AI tool over-selected Asian women job applicants and under-selected Black men job applicants. In a separate Australian study, researcher Natalie Sheard demonstrated that the AI tools used during the hiring process penalized non-native English speakers with accents from other countries more than English-language speakers in the U.S. The Australian human resource professionals interviewed indicated that curriculum vitae analysis systems and video interview systems were common AI tools used to evaluate job candidates. Many companies use facial analysis and recognition software to make workplace decisions, but these tools can exacerbate existing racial disparities. There are a few different reasons why bias creeps into the AI tools used for hiring. The first is faulty training data. According to IBM, machine learning that is trained on samples that are homogenous and lack diversity will reproduce bias. In the aforementioned Australian study, the researcher noted another way bias can creep into these systems: an algorithmic model may prioritize characteristics and traits that are typically associated with dominant cultural norms, disadvantaging non-white job candidates and those with less traditional backgrounds and characteristics. IBM argues that when humans are programming AI models, our biases can seep into these models and show up in ways like exclusion bias; AI models also learn and replicate societal biases, which can show up as stereotyping bias. AI hiring tools that end up causing bias can be a costly mistake for employers. Here’s how companies can address biases in AI hiring tools: 1. Require audits of AI tools. Under New York City’s Automated Employment Decision Tools Law, which went into effect in July 2023, employers are prohibited from using “automated employment decision tools” to make hiring and promotion decisions unless an independent auditor reviews the tool before usage. Under the law, job candidates are also required to receive notice that the tool is being used. Organizations should follow similar guidelines and consider implementing AI tools to make hiring decisions only after an outside review from an auditor. 2. Assess AI tool over time. After making the decision to implement AI hiring tools into the workplace, these tools should be continuously monitored over time. A 2025 article from Peoplebox.ai suggests that in order to get the most out of your AI tool, consistent checks are imperative. Assess important metrics to ensure AI tools are addressing the issues they were adopted for. Some questions the article suggests considering: “Has AI helped you hire faster? Are your new hires performing better? Is the candidate’s experience improving?” Also evaluate whether job candidates from certain backgrounds are being filtered out by the AI tool and manually assess these candidates to ensure fairness in the process. 3. Don’t rely solely on AI tools. There should be some oversight when deploying AI hiring tools and companies shouldn’t rely on these tools to make the final hiring decisions. Employees that will be engaging with these tools should receive adequate and thorough training on ethical use and deployment of AI tools. Trust (to an extent) but verify, when it comes to workplace AI tools. It’s important to remember that AI cannot replace humans in the hiring process. MORE FOR YOU We must remember that no workplace tool will ever be perfect. AI is not a panacea for recruitment and hiring issues and should be implemented with care, concern and consideration. AI is revolutionizing our workplaces in a plethora of ways and in the years to come, AI in our workplaces will be inevitable. While the possibilities of these tools seem endless, we must also be mindful of their vulnerabilities and limitations. Editorial StandardsReprints & Permissions LOADING VIDEO PLAYER... FORBES’ FEATURED Video